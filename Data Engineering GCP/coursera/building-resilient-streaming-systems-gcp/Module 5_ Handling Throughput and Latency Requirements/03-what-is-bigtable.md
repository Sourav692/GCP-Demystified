## Bigtable: big, fast, autoscaling NoSQL
So, Bigtable, is big, it's fast, it's auto scaling and it's NoSQL. So it's big. How big? You can deal with data more than a terabyte. This data can be semi structured or can be structured. And it's really meant for data that's very fast changing, that has a very high throughput and you use it when you don't need transactions, when you don't need strong relational semantics. So where do people use Bigtable for? It tends to be used a lot for time series data, financial data, sensor data, data with this natural ordering in terms of time. It also gets used for real-time processing, asynchronous batch operations, and increasingly, it is getting used for data involving machine learning algorithms, especially machine learning algorithms that do continuous training. So with cloud table, you get global availabilities. It's like Pub/Sub again. So you basically get global availability. You can put your service and data where you want but unlike Pub/Sub, unlike BigQuery, it is not cluster free. So you're thinking in terms of a cluster of nodes with Bigtable. Bigtable like everything else on GCP, your data is encrypted at flight, at rest, on the wire, and you get full control of the data, you get the identity access management that's come into the platform. And you get redundant auto scaling storage. So it's all the data that you put into Bigtable, is durable, it's replicated and you can get access to it. So like BigQuery, Bigtable also separates out computing and storage. What do you mean by that? Didn't I just say that Bigtable use clusters? Well, it uses clusters, but those clusters only contain pointers to the data. They don't contain the data itself. So the clusters consist of nodes, these nodes all contain the metadata, the data itself remains on Colossus. It remains on Google Cloud storage. So, if we think in terms of data that's stored in contiguous rows. So you basically have rows of data and those rows of data that are stored contiguous, we talk of them as tablets. So all of those tablets of data are stored on GCS. And what the nodes contain, is essentially pointers to those tablets of data. And so whenever the clients want to do processing, they basically say, "Here's the processing I want to do." And the nodes basically carry out the processing. And the data gets shuffled into those nodes to basically do the computation. But when the nodes read the data, they essentially read contiguous rows of data. This is going to be important when we think about the design of Bigtable. How to optimize the performance of Bigtable. 
