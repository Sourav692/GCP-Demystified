## Managed stream data processing: A common configuration
Recall a reference diagram for stream data processing on GCP and in that reference diagram, we are now going to be talking about cloud pub/sub, which is our message bus. We'll use pub/sub to ingest our traffic data in the class hands-on exercise. Pub/sub works very well with streaming data. It provides high ingest speed, durability, fault tolerance, NoOps, provides auto scaling. So it's the way that people deal with the first challenge of being able to ingest variable volumes. So pub/sub is global, it's multi-talented, it's managed, it's real time and it's a messaging service. So what do these things mean? Well, first of all, pub/sub is discoverable. What that means is that pub/sub handles a discovery of subscribers who are interested in messages from specific publishers. So the subscribers and publishers don't need to find each other directly. They can just go look in pub/sub for the list of topics for example. What this also means with discoverability is that moves are handled. So if a different publisher starts publishing to the same topic, no problem. Turndowns can be handled. So again if there are three publishers publishing to a topic and one of them goes away, no problem you're just listening to the topic and the messages will continue showing up in the topic. Second aspect of pub/sub is that it's highly available. You don't need to worry about as a publisher whether or not subscribers are around to receive the messages. Pub/sub absorbs the requirements of handling any subscribers that can't keep up with your pace. So as a publisher, you just keep publishing. You don't need to worry about whether pub/sub is around or whether the subscribers are around to receive those messages. Third aspect, messages are durable. Messages are going to be saved to be delivered later if the subscribers aren't around to receive them. This is up to seven days. Finally, pub/sub gives you global scale. It's a global messaging service. And it also gives you low latency.
## Cloud Pub/Sub connects applications and services through a messaging infrastructure
So Pub/Sub is a way to connect applications and services through a messaging infrastructure. So you don't use Pub/Sub to store data permanently. You don't use it to process data. You don't use it to analyze data. There are other products for that. Pub/Sub is about capturing data and distributing data.

So Pub/Sub is this single global service. It offers you high, consistent throughput and latency. It's serverless, it's global. There's only one Pub/Sub. So you don't have a Pub/Sub per project, or per user, or per domain, You're not starting up a cluster of machines on which you run Pub/Sub. There is just one Pub/Sub, its global. Just like there's only one global Bigquery that's serverless, there's only one global Pub/Sub that's serverless. But then whenever I start talking about Message Bus, a natural question is going to maybe pop up. So let me just answer that.

We already have a single, global way of connecting applications, that's our network. So isn't that network enough?

Why do we need Pub/Sub too, in addition to having a network? Well with the network alone, if two applications need to communicate, both applications need to be online and available all the time. So without Pub/Sub, it's as if you were in the world of a telephone.

If the subscriber is not around, the message doesn't get transmitted. If the publisher is not around, the subscriber has nothing to process, right? So everything grinds to a halt unless both parties are online and available all the time. With Pub/Sub though, it's like the world of email. And just like with email, senders and receivers don't need to be online at the same time. So Pub/Sub delivers messages instantly as if everyone is online, and safely holds them until they can be delivered if the subscriber is not online. So this is a way that Pub/Sub helps you deal with spikes. Helps you deal with variable volumes.

## Pub/Sub simplifies event distribution
Pub/Sub essentially simplifies event distribution. Rather than applications talking directly to each other, everyone essentially just talks to the Pub/Sub system.

The Pub/Sub is a way of getting asynchronous communications. The publisher never waits, the publisher keeps publishing to Pub/Sub. And if you have two subscribers, one of which is fast and is able to consume the messages as they're produced, then great. The slow subscriber will get the same set of messages but gets to consume them at it's own pace.

So messages are delivered instantly to subscribers that are online and available. But if the subscriber is not online, the messages are kept in Pub/Sub and retried for up to seven days. If a subscriber is down or if it's overloaded, or for any other reason.

So this means that if you are using Pub/Sub you can avoid over provisioning for spikes. You don't need to maintain 1,000 machines because for 1 hour every day you will have traffic that requires 1,000 machines.

So you can avoid over provisioning for such spikes. So this gets to our challenger on variable volumes. Pub/Sub, because it holds messages and delivers them when the subscribers are ready, Pub/Sub service as a smoothing mechanism. And this way subscribers don't get overwhelmed.

## Pub/Sub features
So a quick summary of Pub/Sub features. First, it's a single global service so you can use it to move data from anywhere to anywhere. It's fully managed. There's only one Pub/Sub globally, and you basically have around the clock up steam to make sure that Pub/Sub itself, you can rely on it. Messages and Pub/Sub, are guaranteed to be delivered at least once to everybody who subscribe to it. So if you have a subscriber, the message will get delivered to the subscriber, but the guarantee is that this is at least once. In other words, it's possible, not likely but possible that you will get duplicate deliveries, and second thing, the order isn't guaranteed. Right. So you don't get to have both low latency and order delivery. You've got to choose. So Pub/Sub decided, low latency we'll give you the messages as quickly as we get them, but the messages are all going to be different sizes and smaller messages are going to be received typically before very large messages in the same queue. So order isn't guaranteed, and you could get duplicate messages. Are you cringing? Is that going to make things hard? Well, this is why it's important that the next step in our reference architecture is Cloud Dataflow and Cloud Dataflow is going to help us get over these hurdles. So Dataflow is going to give you exactly once processing. So how does it matter if the message might get delivered twice? If we can guarantee that the message gets processed only once, and Dataflow will help you deal with late or unordered records. So again this is fine and it's fine, because the next step in a reference architecture, is to use Dataflow. So this is kind of how the products help each other. Pub/Sub doesn't guarantee ordering, but Dataflow can deal with unordered data. Pub/Sub only guarantees at least once delivery, but Dataflow can support exactly once processing. Third thing, is that Pub/Sub is fast. You can get in the order of hundreds of milliseconds of latency, and it's scale-able from one kilo byte per second to 100 gigabytes per second and with that scale, you get consistent performance whether you're processing 1,000 bytes a second or you're processing 100 gigabytes per second. And Pub/Sub supports fan in fan out whether you have multiple subscribers listening to a single topic, or you have multiple publishers publishing to a single topic, both of them are supported. It also supports both push and pull. So in other words, subscribers can ask to be notified or they can keep checking whether there is a new message in the topic, and in terms of interacting with Pub/Sub, you have two types of client libraries that you can use to publish into Pub/Sub or subscribe from Pub/Sub. You have hand-built libraries in Java, Python, C#, Ruby, PHP, Node.js. At Google we call these "silver languages." So these are the ones that are going to support that. Hand-built custom-coded libraries. But in addition, any language that GRPC supports, because the communication protocol that Pub/Sub uses is GRPC, so any language that GRPC supports, you get an auto generated client API for that language. 
