So what is the Google Cloud platform?

Well, let's start out by talking about what cloud computing is. When I started out in computing a couple decades ago, everything that we did was on-premise. So I had a work station, and this work station was literally under my desk. And if I needed to run a program, I would run it on that machine. If something happened to the machine, I would yank out the power cord, I would plug it back in. I owned the machine, I managed the software on it, I installed everything. I had root accounts on that machine. It was all mine.

I managed the software data, Christie did the networking, I paid for everything. That's essentially the on premise computing. But at some point, things changed and it became well you don't have, let's not hide our machines under our desks anymore. Let's go ahead and take all of our machines, put them in this nice data center. So we had a new building, we had data center and we basically had all of our machines in that data center, we still owned the data center, because it was just another floor of our building and whenever we would have visitors to our lab we would take them and very proudly show them this is where all of our computing happens, right? So we had our data center, we owned the hardware, but the electricity, the networking, the physical security of that place, that not everybody could walk into that data center. All that was managed by the people who managed the data center. But my group still paid for the hardware. We essentially paid a portion of the data center costs, in terms of a portion, quote unquote rent, if you will. But we essentially still own those machines. We control those machine. We install the software on them. We decided when those machines would get upgraded.

But we had kind of given up was direct physical access to those machines. Now if you think about it, this evolution from things being completely under my desk to being slightly out of reach but something that I'm still controlling. The phone for data center it's just the, cloud computing is the next step of that. And with cloud computing the big cloud vendors, whether it's Google or Amazon or Microsoft, they own the hardware, they manage the electricity, they manage the networking, they manage the physical security into those data centers.

But, you don't own the hardware even, right? So what you end up doing is that you ask for some computing resource.

And as we see later, the computing resource could be a virtual machine, but in many cases, you prefer it not to be virtual machines. You don't want to work at such a low level, where you're spinning up VMs and spinning them down, you want to think in terms of higher level constructs like here is a job that I want to run. Or here's a SQL query that I want to execute, right. But anyway you basically you have some kind of computing that you need to do. And when you need to that, you ask for resources to carry those computing out and you pay only for those resources that you use. And the whole cloud is a shared resource and you get those resources for the time that you need and you give them them back, and you're not worried anymore about not using it or basically how the over-provisioning servers that you're not using or not having enough of a computing resource when you need it, because somebody else is using it, etc. Right, so the whole idea behind cloud computing is that you have an available resource whenever you need, and you're not paying for it when you don't.

So why is Google in the cloud business?

This is our mission,

it's to organize the world's information, make it universally accessible and useful.

What does that have to do with cloud?

Doesn't seem that cloud computing and organizing the world's information have anything in common. So why is Google in the business of cloud? Well, it turns out that if you need to organize the world's information and make it universally accessible and useful, there are some things that you have to do.

One of the things that you have to do if you are going to organize the world's information, because there is a lot of it and it's keeps on growing, is that you have to build extremely powerful infrastructure.

There is a statistic that blew my mind the first time I heard about it.

Of every five CPUs that are produced in the world today, year on year, Google buys one of them.

Think about that for a second. Google buys one in every five CPUs that's produced year on year. Goes into our infrastructure. So you can imagine how powerful that infrastructure is that we have to build in order to organize the world's information. But that's the physical hardware, right? In addition, we have to make it universally accessible. And if you want to make information universally accessible, you have to build global data centers, you have to build a global network so we have private fibers between all the continents, and you need to have edge locations in a lot of different countries. An edge location is essentially this idea that if somebody's accessing your resource, say from Africa for example, the second person who's trying to access that resource shouldn't have to go across the world to go get the resource again. They should be able to get a cached version of that resource from an edge location. So you need to maintain edge locations, and edge locations are in a lot more places than the data centers. But within the data center also, the design of the data centers is such that any two machines in the data center are just a hop away. That you can basically have some. If you look at the East West cross-section versus, so if you look at the network bisectional bandwidth between machine and google data center it's more than petabit a second. So now you're looking at an extremely fast networking and extremely global infrastructure that needed to get built in order to make that information that we had collected and organized universally accessible. That's the physical part of it.

In addition, we've tended to run into problems of large amount of data ahead of most other people, most other companies in the world. So what that has ended up doing is that we have ended up innovating in data technologies, pioneering many of the alternative techniques that you're all familiar with now. So, for example, GFS, the Google File System, and Map Reduce, those were two papers that came out of Google research.

And they form the basis of what?

Yup. HDFS, the Hadoop Distributed File System is based on the Google files system GFS. And Hadoop itself, the MapReduce frame work is based on the paper by Sanjay Ghemawat and Jeff Dean on MapReduce that's published in 2004.

And, of course, HDFS and HADOOP basically led to the whole ecosystem of a bright and open source at DOOP Tools that are available in the world today. Something to kind of realize is that even though we published this paper in 2004 in MapReduce, by about 2006 we were no longer creating new MapReduce programs. We had moved on.

Why had we moved on? Well, some people realized that the whole MapReduce framework the way it works, is that if you have a very, very, very large dataset, you take that dataset and you chop it up into small pieces and you store those pieces on different compute nodes. Close to the compute, and then you basically have each of the compute nodes doing their little bit of processing on their local data. Those are the map operations. And then take those results. You combine them and then you basically do processing on it. But the key point is that you have to take your data set, and you have to shard it, or split it, across all of the computer nodes, which means you are all decisive of your data sets and decisive of your computer nodes are intimately tied together, and that kind of limits your scheme, because you are often wasting a whole bunch of computer nodes just because you need to store your data there. Or if you need to process some data you can only process it on the compute nodes that already has that data.

So this changed. And so this is part of the innovation and data technology that came about such that GFS, the Google file system, got replaced by Colossus, which is the current file system. Of course, there have been enhancements in Colossus all along the way. MapReduce got, not changed. So, we don't do MapReduce at Google anymore. Instead, the data processing technology of choice are Dremel and Flume, and those are both externalized in Google Cloud as BigQuery and Dataflow, that we will look at.

So the point is that with all of the innovation that's happening at Google to build our own infrastructure, with Google cloud we're opening up that innovation such that you can use it. So Dremel, which I talked about that In 2008 is the basis of Big Query. Flume, the thing that started in 2010, it started in 2010, but it has continually gotten enhanced. So Flume and Millwheel, etc., they all form what is now externalized as data flow. And tens of flow 2015 forms a basis of cloud ML. CLoud ML is a whole state and in flow solution. Similarly you have pop sub which has been released as itself. And spanner now in alpha etc. So you basically have all these innovations that continually get released into Google Cloud. So, one of the things is that if you're working on Google Cloud, you basically have access to all of Google's data processing capabilities.

Now, I talked about how the Mapreduce that we used to use in 2004, we don't use anymore.

And, I kind of mentioned that one of the reasons that we don't use it is because not produced tends to be limited by the number of compute nodes that you have, and that we have better solutions now in the form of big query and in the form of data flow. And that illustrates a key point.

If you're doing cloud computing today, many times though what you may think of as cloud is essentially the change from core location to a vitalized data center. Remember the slide that I showed early on that said what is cloud computing? And I said cloud computing is evolution of you going from things that are being on premise to being on a data center, where you know you basically still own the hardware, but part of the management of that hardware has gone away and that with cloud computing you don't have to own the hardware you don't have to manage any of it. You just get to get the resources that you need. Right, that is the idea. But if you are working in the cloud at the level of virtual machines, if you're saying, I'm going to spin up a VM so I can run this job and I'm going to reserve this VM for months on end so I can keep running this job, at that point, you've lost much of the benefits of the cloud. The cloud is hugely beneficial, if you are running things ephemerally, if you're running things just when you need them. So that's kind of what we're talking about when we talk about now a virtualized data center is your second wave of cloud. It's not yet getting the full benefit of the cloud. The true benefit of the cloud happens when you're using the cloud in an elastic completely global way. And what I mean by that is that you should be able to auto-scale your clusters, you should be able to do distributed storage, distributed data processing, distributed machine learning. If you have a job, and that job can be done on a thousand machines in seconds, you should be able to do it on a thousand machines for ten seconds and just pay for that. You shouldn't have to go ahead and create a cluster of 10 machines, and certain process that job on those ten machines for 10 hours or twelve hours or whatever it takes you.

The whole idea behind an elastic cloud is this idea that you get to use your machines just for the time that you need them, and then when you don't need them, it's not on your bill anymore.
