0:04
This is Arthur C Clarke. And one of his famous quotes is that, any sufficiently advanced technology is indistinguishable from magic. And to me, that perfectly captures my feelings when I first encountered BigQuery. BigQuery is magical. But rather than me telling you what the query is, let's see it in action. So I'm going to go to bigquery.cloud.google.com. And in the BigQuery console I'm going to compose a query and that's basically going to be my query. I'm going to be searching on 10 billion rows of the Wikipedia data. And for every row, I'm going to do a regular expression match on the title to see if it matches Google. And I'm going to see which language that mention of Google was in, and how many views there were of those mentions. So we're going to look for pages in different languages that mention Google in the title and count the number of views of those. And we'll go to the Show Options, and say don't cache the results. BigQuery by default will cache the results for it for a few days, so that if you rerun the exact same query, you're not paying for it a second time. But we don't want to cheat, so we'll not cache any results. And let's go ahead and hide the options, run the query and 1, 2, 3, 4 seconds, 5 seconds, 6.3 seconds later, 416 GB of data have been processed. And we find out that most mentions of Google that people viewed were that in English and secondly it was in Espa√±ol. I mean, commons is obviously not a language. And the third was in German and Italian, followed by French, Japanese at number 8 and Dutch at number 9, etc. But the cool thing, realize, is that in 6 seconds, we were able to process nearly half a terabyte of data. This is awesome. This is magical. So, this is what we just did, we did a demo of BigQuery. This is a query. We looked at 10 billion rows of data. We did selection, then we grouped it, we ordered it and we got all that done in about 6 seconds. So what BigQuery gives you is an interactive way to analyze petabytes of data. The queries that you write can be standard SQL, SQL 2011, so it's a very familiar language to most people. You can also write User Defined Functions in JavaScript. And you can access data, CSV data, JSON data on Cloud Storage and run a query on them without actually ingesting them into BigQuery. Ingesting data into BigQuery though is very straightforward. If you have your data on disk, if it's small enough data, or if you have your data uploaded to Google Cloud or in Cloud Datastore, it's as easy as going to a web console and basically saying, here's my file. This is the destination. Here is a schema. These are the columns. These are the types. Load them in. It's very, very, very easy. And what you can do from the web console, you can also do from the command line using the BQ command. You can stream data in with Cloud Dataflow. And this is very, very helpful if, for example, you're receiving sensor data in real time, blog data time in real time, you can process them with Cloud Dataflow and stream them into BigQuery. And even as the data are streaming in, you can run queries on that data. Besides batch data on cloud storage or streaming data via Cloud Dataflow, a third option is to not load the data into BigQuery at all. Is to leave your data in raw form as CSV files or JSON files or Avro files and set up what's called a federated data source. You're basically creating a link to it and saying, here is the name, here is the schema, there is my file, so don't make a copy of that file and directly query that file. That last option there, Google Sheets, is extremely interesting. The idea is that you can have some data in a Google Sheet and query it with BigQuery. And now you are saying, wait a second, a Google Sheet, what? I probably have like 30 rows in my Google Sheet, why would I use a SQL BigQuery query to query it? Well, it's not about the data in the Google Sheet. It's about what you can join it with. So you could, for example, have millions of rows, billions of rows of data in BigQuery and join it with the smaller data that you have in Google Sheets. So you may have your customer data in Google Sheets, your sales data in BigQuery, and you'll be able to basically correlate that customer. Join them with this much more massive data that you have in BigQuery. So being able to join a table in Sheets with a table in BigQuery is extremely powerful. You can also write user defined functions in BigQuery, so you're not limited to SQL 2011. Here for example, I'm calling a method called urlDecode. That method is defined as a user defined function and it's written, it's implemented in JavaScript. And you can have natural JavaScript, so people have done even more very complex things like natural language processing. There's a JavaScript library that does natural language processing, and so they're able to basically write a UDF to process, for example, Stack Oveflow questions, right? So that's free-form text. You can now process it with an NLP API and you can do queries on it. This is also a very powerful feature that makes BigQuery even more powerful than being able to run SQL queries. It's because you can now take JavaScript libraries, that can do a lot more than SQL, and combine them with the capabilities of your SQL programs. You can work with BigQuery from the console, as I just showed you. But running it from Datalab gives you another level of flexibility because Datalab is a way by which you can run Python programs. And the good thing about Python is that it has really nice data analysis capabilities, data visualization capabilities. And now you can basically combine BigQuery with these very powerful graphical tools and data science tools. This is the way it works. You would basically go to a cell and you would mark that cell as a SQL cell. And that basically tells Datalab that this is not Python code that's going to follow, but a BigQuery SQL code. So you say, there is SQL, I'm going to give it a name, wxquery. Then in another cell, which is a Python cell, you would create a query, wxquery, which would basically link to that. Say, whenever I call wxquery, this is the SQL query that I want to run. I want to select the day of the year and all of those things and you supply a YEAR=2015. And what this does is that in this query, wherever $YEAR occurs, that's going to get replaced by 2015. So if we run this query and we will get back a BigQuery result set, but we say take that BigQuery result set and convert it into a Pandas dataframe. Pandas is a Python data analysis library. So what comes back, whether, is a Pandas dataframe. And now all of the Pandas, Matplotlib and NumPy, all of those capabilities that data scientists in Python use, they are now completely available off the result of a BigQuery data set. 
