In the data engineer set of courses in this curriculum, we're going to be looking at how to build data handling capabilities on Google Cloud platform.

So who's a data engineer? A data engineer is someone who enables decision making. Typically, they do this by building data pipelines, by ingesting data, processing data, building tools to analyze data, building dashboards, building machine learning models. So, a data engineer's job is to enable decision making within the company in a very systematic way. And in order to be a good data engineer, you needed to know both programming and statistics to a great deal of depth. But with the advent of cloud services, particularly the fully managed, auto-scaling services on Google Cloud, the amount of infrastructure that you need to know, the amount of programming that you need to know, has gotten a lot simpler. At the same time, the statistics realm has also gotten a lot simpler. You now have libraries that take care of a lot of the low level programming that you had to have and a lot of the mathematical concepts that you had to know, to the extent that you can now program with data, you can build statistical machine learning models a lot simpler, when you're building using these libraries and packages. So, what has happened is that over time, the amount of programming that you needed to know has gotten simplified. So, what we're going to be doing in these sets of courses is that we're going to look at how to build data pipelines, data processing systems, on Google Cloud platform.

In this first course of the data engineer track, you will gain an overview of the data and machine learning parts of Google Cloud platform. And not just in cursory overview. So what we're going to be doing is that in each module, everything is going to be two pronged. At one level, we will look at some products that help you accomplish certain things on Google Cloud. But at the same time, we'll look at very specific use cases, very common use cases that involve machine learning, that involve data processing, that involve data analysis. So if you look at how to accomplish those use cases using this particular products. And we'll do this over and over again. And by the time we're done with this course you will have basically gotten a pretty good overview of all of the moving parts of the data and ML parts of the platform. So let's get started.

Course Overview

In this course I'll be providing a very quick overview of GCP, in particular its foundational parts to compute and storage. And then we dive straight in to providing a deeper overview of the different ways you can process data with GCP. So we'll talk about BigQuery, Dataflow, Dataproc, Cloud SQL, Datalab, etc. So who's this class meant for? It's for meant for what we call data engineers. People who design, build, maintain data structures, databases, data processing systems, data pipelines. Who do extraction, transformation, loading of data, move data from one place to another. Who may be data scientists who are analyzing data, enabling machine learning to happen, maybe even doing machine learning yourself.

People who model business processes, who enable data driven decision making within your company. So if you recognize yourself in any of these things this class is meant for you. It's meant for anyone who'll be working with data on Google Cloud Platform. It's also meant for any decision makers who are trying to decide whether your company should move to GCP and do your data processing on GCP. So this gives you a good overview of all the capabilities that the Google Cloud provides so that you can make an informed decision.

In the course we will now start with an overview of Google Cloud Platform as a whole, but with particular emphasis on the ways you can handle data in the platform. The way you can ingest data, different ways of doing processing of data, whether with map produce, such as with Spark or whether with a streaming mechanism like with Dataflow. We look at BigQuery, which is our auto scaling date warehouse, etc. So we'll give you overview of GCP, but with an emphasis on the data handling parts of it. We'll also then move on to talking about the foundation of GCP and this is computing and storage. Like any computer, and the Cloud is a computer, the two key parts of a computer are the computing units and the storage units of persistent data. And the way that happens on the Cloud is with Compute Engine and Cloud Storage, so we'll talk about both of those.

And then we'll move on to things that you're probably doing today, that you could easily move to the Cloud. We'll talk about the use cases that are quite common that Google provides a good managed environment for such that you can take things you're doing on premise, on your own hardware, and move it to the Cloud quite easily. Because the same software that you may be using Is also present on the Cloud. So as examples of those use cases, we will talk about relational databases in the form of Cloud SQL, which is a MySQL database hosted on GCP. And we'll talk about Cloud Dataproc, which is a hosted version of big Spark hype of the Hadoop ecosystem software processes. So in order to do that we'll look at how to import data and how to query MySQL running in Google Cloud. And similarly, we'll also look at how to take a Spark program, submit it, and have it run on Cloud Dataproc. And the Spark program that we will look at will be a machine-learning program to carry out recommendations. And once we have talked about the use cases that we're talking about, migrating use cases, we will then move on talking about more transformational use cases. These may be things that you may not be doing today, mainly because it may not be possible for you to do them today. So for example, we look at how you could query petabytes of data in a matter of seconds with Google BigQuery. We will talk about how to do fast random access, trading off global consistency versus low global availability. We'll also talk about machine learning. We'll talk about how to do TensorFlow. Maybe you run TensorFlow, but very commonly maybe running it on a single machine. We'll talk about how you'd run TensorFlow in a distributed fashion on the Cloud over extremely large data sets. And then we will move onto just providing a very quick overview of how you would do scalable reliable data processing on Google Cloud with Cloud Pub/Sub, which is a messaging architecture and with Cloud Dataflow, which is a way to execute a code that processes both streaming data and batch data in essentially the same way. And finally, we'll come to the conclusion of the course, and I'll leave you with some resources for further reading.

As an introduction, my name is Valliappa Lakshmanan, everyone calls me Lak. I'm at Google. I am part of the Professional Services organization at Google where I advise customers who are moving to Google Cloud on the best ways to do them. I focus primarily on the big data and machine learning parts of Google Cloud. Before I joined Google, I was a research scientist at NOAA, which is the US weather research organization. It was a cooperative institute between NOAA and the university.

So, I built machine learning algorithms for weather prediction for flash floods, hail, tornadoes, etc. And that's basically what my background is. I have a PhD in Electrical Engineering, and I was working on machine learning for weather. Until about maybe like, three years ago, I took a leave of absence from my university academic job, went to a start-up that was doing precision agriculture. And there, I headed up a data science team that built a rainfall prediction system. And it was in the process of that that I discovered the cloud. Now everything that we had done at the university, this was, remember this was like more than three years ago, it was primarily on premise. We had a cluster of machines, and it was on that cluster of machines that we ran our real time systems. That we did our experiments, that we did our, and machine learning training, everything happened in that cluster of machines.

And then we went to the startup where everything happened on the cloud. We didn't have the cluster of machines, we didn't have any machines. All we had were laptops, and we ran around with our laptops. So anything that we need to do any massive computation that we needed to do would happen on the cloud. And that was when I realized, one of the key economic advantages of running things on the cloud, because whenever we needed to do a large scale study, we would have our data on a tape drive, we'd move it over to our cluster of machines, do it, move it off, etc. And this was a whole bunch of data handling. And what kind of discovered was the kinds of things that would take us four years to do on-premise in our own cluster, we were doing every two weeks at the startup. And it was not that they were any smarter at the start of the [INAUDIBLE] than we were at NOAA, or the government. It was essentially that rather than do things on a limited environment, we would basically scale thing out to a lot more machines, and get things done a lot faster. And if you're looking at innovation that happens, things that take four years now take two weeks. The number of things that you can try, and the number of ways that you can do it, just explode. And the speed of innovation just becomes a whole lot better. So, when I was looking at, okay, what do I do next?

Now that I discovered the cloud, and I discovered what being able to do very fast innovative cycles with machine learning on the cloud could achieve. I wanted to be at a place where I could do both ML and cloud and that was Google.

And so my goal for this course is to get you all as excited about cloud, about big data and about machine learning as I am.
