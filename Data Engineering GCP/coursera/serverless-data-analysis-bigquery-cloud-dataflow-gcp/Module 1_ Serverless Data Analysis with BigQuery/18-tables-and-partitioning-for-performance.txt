The other thing that you should think about is whether you can use wildcards. So, you can query multiple tables using your wildcard, and the number of tables that you're matching obviously affects your performance. So, when you do your query, if you have multiple tables with very similar names, you can use wildcard tables. For example, you can say from bigquery-public-data.gsod* and that just matches all of the tables in noaa_gsod that begin with the string 'gsod'. And because we're now using wildcard, you need to backtick to make sure that no, we're escaping it. Also, when you're doing these wildcards, the richer your prefix, in other words, the more information you can provide to BigQuery, the faster it's going to be. So, try to use... try to specify as much of the common letters as possible. But where we talked about wildcards, there is another option that you have, which is partitioning the tables by timestamp. So you can specify a particular column in your data, that is, your timestamp, and you can say, "I'm gonna stream this data in, and I would like you to partition behind the scenes based on timestamp." And timestamps will give you similar performance benefits as having a sharder table, right? So if you have a sharder table, you would basically be splitting it and maybe doing your queries only on a few shards, a few dates. Well you can do the exact same thing with time-partitioned tables. So the way time partitioning works is that, you would say, 'select from sales' and sales is just your table but you would say the partition time is between this timestamp and the other timestamp. So it's very similar to having a wildcard table where the wildcard is your date except that your bigquery dataset only contains one table.It's just that it happens to be partitioned by time, by default. Now one of the things that you have to be very careful about is that, unlike a wildcard table, it is not obvious to somebody who looks at the sales table that there is a partition column that exists and that ideally, for performance reasons every query on the sales table includes a partition type. So that's one of the things that, that's one of the trade-offs that you have to keep in mind; wildcard tables involve lots and lots of tables that can get somewhat annoying. Partitioning gives you a cleaner interface just as one table but it imposes some cognitive load on everybody writing queries to remember that this thing contains a partition column. The bigquery console also helps, it warns you if there is a partition, if there is a partition column and you're not using it in your query. But it's just a warning it's not, you can obviously ignore it and actually do it if that's exactly what you want to do. 

So, in order to improve query performance, you have to understand the query performance. And the way that you can do this, is to run your query and say, well, what did my query do? Explain it to me. The other way is to monitor the query as it runs using stat driver. So that you can monitor how the CPU usage and desk usage

So this is what an explanation plan looks like, so you would have multiple stages in your query. So every query will know, typically you can look at your query and you can say which part of the query corresponds to what stage. Or you can just go ahead and click on the arrow. For example, this arrow and that it shows you the exact part of the query that falls into stage one. And with every stage it's waiting for the data to become available from the previous stage. It's then reading the data, it's then doing the computation, and it's writing the data to the next stage. So then, this stage, meanwhile, is waiting for all of the data here to be written out, if necessary. And then it's reading it, it's computing it, it's writing it out to stage number three, and so on. So that's essentially what happens. And what you should look at here Is a number of rows that are being processed at each stage. And what you want again, is for the number of rows that get processed to keep decreasing very drastically. You can also look at these colors, right the length of the bar here indicates the time taken by the longest stage, longest part in that stage. So for example here the wait is what takes the longest time, read takes about 80% of the wait time, compute takes about half of the wait time, and write takes about like a fifth of the wait time. So the wait time is 100% and all of these are essentially fractions of that. In this case, there is no skew. And I'll talk about how deep the graph would look like if there is significant tail skew. In this case, there is no tail skew, right? So you basically can look at in stage one most of the time is spent waiting. And in stage two, again, most of the time is spent waiting. And there is the read, read pretty much takes up no time at all. That makes sense because, hey, we're just reading one item, it can't take any time. But on the other hand we are waiting for that one item to become available, and so that takes quite a bit of time. The computation on that one item is very simple and straightforward and then it gets written out. So that's basically the way you read your explanation plan. But remember I said something about tail skew. How do you know if there is skew associated with any particular stage? The way you do this is that if there is skew, the graph would look something like this. So you basically have the overall length. This is again, the longest step in that stage, read or wait or compute. And then you basically say that the maximum of this is this much and the average is that much. And so if the maximum is dramatically bigger than the average, then you know that you have some things that take a long time to process, compared to the typical thing. So that indicates that you have tail skew. Something that looks like this, where the average and the max are identical has no tail skew. And again, in the graphical interface you actually won't see the words average and max you just have to realize that there are three shades here. So the darkest shade is the average, the middle shade is the max, and the lightest stage tells you the fraction of the overall that this thing is using.
