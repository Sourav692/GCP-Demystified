0:01
Now imagine that the threshold is 0. Remember that every classification model gives you a number between 0 to 1 and by thresholding it is where we decide if it's of category 0 or category 1. Let's say that we threshold this thing at 0. If we threshold our classification model at 0, then what we are essentially saying is that every parking spot is empty or every image has a cat.
0:32
If that is the case, then we will definitely find that all cats we will definitely find all parking spaces. So our recall is going to be 1, however, our false positive rate is also going to be 1. That's because everything that's not a cat, we're still going to call it cat, and every parking space that's not empty, we're still going to say it's empty, right? With the threshold equal 0, we're saying that everything, everything is what we are trying to find.
1:08
On the other hand, if threshold is 1, then you are at the bottom left of the chart, and if threshold is 1, then you're saying that nothing is a cat and no spaces are ever empty. And if that's the case, your recall is going to be 0, but so as your false positive rate. And in between you are going to get somewhere on this curve where maybe if the threshold is 0.4, then you get a recall of 0.5. And if the threshold is 0.6, then you get a recall of 0.2. So by travelling along this curve, you can pick a particular recall and by, say if you wanted recall of 0.8, all that you need to do is to go find the location on this curve and that tells you what threshold it is that you need to use. So by changing the threshold you can get any desired recall that you wanted and works the same for precision. So just looking at a precision or just looking at a recall doesn't tell you much about how good the model is. So if you have two models and you want to say, is this model better than the other model? What you tend to do is to try out every possible threshold, and plot to the recall versus a false positive rate. And the further that this curve is to the top left, the better the model is. What this means is that your trade off is going to be less impactful. So for example, in order to have a recall of 80%, then you end up with a curve on the yellow curve with a false positive rate of only 10%. Whereas in order to get a 0.8 recall with a purple curve, you need to live with a false positive rate of nearly 40%. A line that basically goes like this, that connects the diagonal, that reflects a worthless model, a model where you really don't have any skill. So the reason that you can get any precision or recall is because you can choose the threshold. So the other way to pose this is
3:37
given a business value that you want to achieve certain recall. You can get that with any classification model by choosing an appropriate threshold.

0:00
So, based on these concepts, go ahead and write down definitions for all of these ML terms. The MSE, or the mean squared error, is the error that you use for optimizing a regression model. A cross-entropy is error measure that you use as a last function to optimize a classification model. Accuracy is the fraction correct. It's a way you report the performance of a classification model when the data sets tend to be balanced. Precision is the measure of skill that looks at the accuracy when the machine learning model says it is of category that you're trying to find. The recall is the accuracy in the machine learning model. It's the accuracy in terms of how well the machine learning model can find the things that you're trying to find. So, you tend to use recall when the things that you're trying to find are very rare, and you tend to use precision when the things that you're trying to find are very common. Again, if it's balanced you use accuracy, if it's unbalanced and you tend to have lots of cats in your images you tend to use precision. If you will have very few cats in your images you tend to use recall. The ROC curve is a curve of false positive rate to false negative rate, and you use it so that you can pick the right threshold for your classification model. 
