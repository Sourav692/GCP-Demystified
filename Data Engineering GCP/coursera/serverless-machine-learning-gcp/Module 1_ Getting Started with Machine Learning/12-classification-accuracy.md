0:00
From the confusion matrix, you can then calculate measures of skill. Let's say for example, that we want to classify the cats from these sets of images. And the machine learning model tells us that
0:17
the first image, the second image, the third image are all cats. And then it says, that the image on the left-hand side is not a cat, and that the image with all the shoes is not a cat, and so on. So let's say this is the hypothetical results from machine learning model, what is the accuracy? The accuracy is a fraction correct. So the first image is an image of a tiger, the machine learning model said it's a cat, so that's wrong.
0:52
On the other hand.
0:56
The machine learning model looked at the image of all of the shoes and said it's not a cat, but there is a cat hidden there on the second shelf. And because there is a cat, and the machine learning module said there is no cat in this image, that is a wrong prediction. So this is essentially what we do, we go ahead and take their images and figure out which ones are truly cats, that the image said was, the image ML model said was a cat, and which things that were not cats, it did not find. So, in this case there are three correct detections. And of the total of eight images, our accuracy is three out of eight, or 37.5% or 0.375.

0:00
The accuracy is fine and that's the one that you're going to use most of the time. But if that data set is not balanced, accuracy starts to have a problem. So I think that you want to create a machine learning model that needs to identify empty parking spaces in your parking lot. So there are 1,000 parking spaces in the parking lot, 990 of them are taken. They're occupied. There are 10 available. So this is the true situation. But now, we have a machine learning model that identifies only one of these 10 available spaces. What is the accuracy of this model? Well, there are 990 occupied spaces and the machine learning model correctly identifies that these 990 spaces are occupied. In addition of the ten empty spaces, the machine learning model correctly identifies that one of them is empty. So in total, the machine learning model is correct,991 times out of 1,000. So it's accuracy is 99.1%. But I think we recognize that something isn't right. But that's because this dataset is not balanced. There are 990 of one class and only 10 of the other class. If we had approximately balanced number of occupied spaces and empty spaces, we wouldn't have this problem. So if you have unbalanced dataset, you want to start looking at procession and at-

0:00
Precision is the positive predictive value, the accuracy when the Machine Learning model says, it's cat. How many times is it correct? So, now we only take those images for which the ML model said cat. And in this case, there are five of those images, and we take each of these five images and we calculate the accuracy on only of these five images. So in this case, the ML model is correct twice, and wrong three times and therefore, the precision it's two out of five or 40%. Now, let's go back and look at the parking space problem again. What is the precision? How many times did the machine learning model say that a space is empty. Once, and of those one images, how many times was the machine learning model correct? One. So, one out of one, 100%. So, the precision of a parking space problem is 100%. So that's not it. That's still not corresponding to our intuition. So precision is one aspect, the positive predictive value. The other aspect that you would want to look at on an unbalanced dataset is recall. Recall is a true positive rate. So, this is where you go ahead and you find all of the cats, the images of all the cats, and say how many of these cats does the ML actually find. So in this case, there are four images that have cats in them, and we remember that this thing with the shoes also has a cat. So there are four images that have cats in them. And of these, the ML model finds two, and therefore the recall here is two out of four, or 50%. Go back to the parking example, what's a recall? Well, there are 10 empty spaces. We find one of those empty spaces and therefore, the recall is one out of 10 or 10%. So, bottom line then, if you are developing a classification model, cross-entropy is going to be the error that you're going to use to do the optimization. But precision and recall, are the measures of scale that you will use to describe your dataset, the performance of your ML model if it's unbalanced, and accuracy is the one that you will use if it's a balanced dataset.

0:00
The thing to realize is that precision and recall by themselves don't tell you much about how good the model is. And the reason is that, remember that your classification model gives you a number between 0 and 1.
0:18
Now, as a conceptual experiment, assume that we threshold the output of our model at 0.999999, right? So just really, really, really high.
0:31
That means that everything below 0.9999 is going to be classified as class 0, and anything above 0.9999 is going to be classified as of class 1. So in effect, the machine-learning model is going to say everything is of class 0. Now, if you say everything is of class 0, No. How many times are you going to be correct when you do say if something is 1? Are you going to be correct all the time, right? So what this means is that by changing the threshold, you can get whatever recall or precision you want. So if you set your recall, if you set your
1:21
threshold to be nearly 1, your recall will be 0, and your precision will be 1. And if you set your threshold to be 0, your recall will be 1 and your precision will be 0. So if you want to device a machine-learning model with a recall of 75%. All that means is that you have to go ahead and set your threshold to be, say 0.75. 
