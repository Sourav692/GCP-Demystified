0:00
Now that we've talked about the need for, so what we are gonna do in this class is that we're gonna do the right-hand side. We have enough data. We're gonna do the right-hand side. We're gonna basically take our original data and split it into training, validation, and test. OK. So that's what we are gonna do in this lab. But what dataset are we doing? This is a problem that we're gonna do in machine learning today. OK. What we want to do is somebody picks up, somebody says, "I want to go from JFK Airport in New York to Wall Street. What's my taxi fare gonna be?" So, we want to predict the taxi fare given the pickup location, the drop-off location. Fair enough? That's basically it. Now, if you think about it, it turns out that from here to here, there are, like, three routes. They go through different tunnels, different bridges, they have different tolls. We're gonna add the toll to the thing that we want to predict. And at different times of day, they're gonna actually be different because of traffic conditions, they're gonna take different amounts of time. And New York City charges are based on distance and time, so we have to learn typical traffic patterns. We have to learn the tolls. We have to learn the typical distances between any two pairs, any pair of points. At the end of this, essentially what we will have done is that from a dataset of taxi rides, we would have inferred the map of New York. OK. By just the fact that we know the pickup location, drop-off location, and what they've paid, OK, because that's what is needed. So it looks like a very simple problem. This is actually a horrendously hard problem. All right. It's horrendously hard because your dataset is so simple: pickup location, drop-off location, price. But from that, you have to infer so many things. You have to learn about different routes, you have to learn about when different routes are taken, and so on. Right? So we'll start off with a, like, very simple benchmark. That is, given two points, let's compute the distance, and let's compute what the taxi fare is for that distance. And then we're gonna say the machine learning model has to do better than that. And that is gonna take us the whole day because the initial models that we're gonna build are not gonna be good enough. OK, but it'll help us learn the importance of feature engineering, the importance of model architectures, doing all of those things. So I don't want you to get, just to think this is an easy problem. Again, this is probably one of the hardest regression problems that you'd be faced. Most of the problems that you work with in real life will be a lot easier than this. You don't have to go through all of the things that we go through. But, you know, in a class like this, you want to pick a hard problem so you know all the things to do, right? So, that's basically what you're gonna do here. So, lab 1a.


0:00
So in the lab, what you did was that you set up a dataset, okay? Ultimately the taxi dataset is like a billion rows, but for experimentation, we basically went ahead and picked like 10,000 of them, just to get started, because we don't want to have to trawl through a billion rows each time. At the end we'll basically do it and even then we won't to a billion, I think we'll do like a million or a million and a half rows, which is probably enough to get pretty good results out of it. Okay, but also because doing a much larger dataset takes a long time. So I'll just show you what happens when you run it on the full or half of that full dataset.
0:40
The key things that we did in that lab were these, right? Number one, we explored the data. We figure out what parameters to use. And we wrote out the CSV file from our BigQuery to make it easy to work with, right? So we don't want to keep hitting BigQuery every time there's cost associated with it. Also we want to be able to show our data when we do different things with it. It's much better to get it as a simple CSV file. We have easy readers out of that intensive flow.
1:09
The next thing that we did was that we built a benchmark. What was the purpose of the benchmark? >> [INAUDIBLE] >> Yeah, we know if you're getting better or worse. So more importantly, we know if we are actually doing something useful, right? If we can't even beat a heuristic, right? Why are we using machine learning, right? So it's always, always a good idea to know what your target is, okay? And I can't emphasize that enough. You don't want to say, I have some data I'm going to do ML I'm going to do it. Think about a very simple rule a heuristic that you can do on your data and keep that as your load stereo benchmark because as it will turn out, it can be easy to think that you actually have a machine learning model. But it may not be very good. And unless you have that simple rule as a benchmark, a something to base your decision on, is this good enough or not. It can be very hard to convince yourself that you need to put more effort into specific aspects of your ML module. So have a benchmark available so you know what's doable, and then look at building ML models and making them better. So the benchmark was an absolutely essential part of that lab, okay? And so remember that on that benchmark our automacy was what? $8, right? So we are going to keep that around because our first few ML models are not going to be better.
2:40
Sorry to break the suspense but they are not going to be better, right? We're going to spend quite a bit of time building ML, learning ML, writing simple models. Just throw the data at it, do an ML model, it's not going to be better. We're going to have to spend more effort, more insight into it, to get that 
