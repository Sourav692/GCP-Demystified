Lab: Adding Machine Learning to Big Data Processing
In this lab, you integrate the machine learning APIs into your data analysis. You will write the code to use the Speech, Vision, Translate and Natural Language APIs. You will see how to execute these APIs on your Spark clusters. You will also integrate these services with BigQuery and Storage.

What you learn
In this lab, you: ...

Enable the Google Cloud Platform machine learning APIs
Find specific text in a corpus of scanned documents
Translate a book from English to Spanish using the Translate API
Perform sentiment analysis on text resulting from a BigQuery query
Begin the lab
https://codelabs.developers.google.com/codelabs/cpb102-machine-learning-to-big-data-processing/


So the last part of the leveraging unstructured data had to take a look at using a Google cloud data lab notebook and have it use several of Google's machine learning APIs. So let's go ahead and review the highlights of that. Okay. So a little bit of set up we had to do in this was to make sure that we had a data lab running which we did from the previous exercise and we were going to use the data lab notebook, data lab notebooks training data analysis course and unstructured, and then the one called ML tests, so that's the path. So let me shift over to my data lab. So here I have data lab and I'm in the data lab notebooks training day analysis course unstructured. You could have actually copy that URL up here as well just underneath the tree. So it's the IP address 8080 and connected. Now notice before I start here, though notice my PySpark-test-solution is still green, that's because that workbook's actually running. I might have close that tab but it's still running in the background. Now I'm going to want to clear that up first, so I'm going to want to click in the upper right corner of the running sessions icon and I want to close any open notebooks I have, just so that I can- my compute can focus on the notebook that I'm about to open. Okay. So give it a second here. You'll come up with a list and I'm going to shut down that notebook. Okay, so good. You can close that, and now I'm going to open up ML test solutions. Now the first thing you notice when you open this up is you may already have a bunch of results showing in the notebook because it kind of saved what was there last time it ran. So there might be some blocks of information under some stuff. So it's always good to hit clear, and what that will do and actually do clear all cells and notice how it kind of zapped the stuff under the bottom. And that way you're not seeing any that previous code because when you run the section you know like this print API key. Well that would just show the results from last time. Now, speaking of the API key, we're going to need an API key so Google knows to build the usage of these APIs to us. So we better go over to in Google cloud platforms web console click the dropdown and we want to choose pop up- API manager. Now, first thing we want to do is go over to our credentials and we want to go ahead and create a credential. We need an API key, and what's going to happen is after second the API key will show up. Great. I'm going to want to copy that and I want to put it somewhere handy. And I got one from earlier, from another demonstration so there we go. So that's my API key just in case I need it again. So I need that inside of my data lab, so that's his first line I need to put that there so that way when I use machine learning it can go ahead and build it back to my account. Now the next thing we are going to need, is we're going to need our project ID brought over in here. And so luckily, I've got my qwiklabs project here and actually looks like I might've already done that in this workbook. So that's good. So now we got the API key, we got the project key. Now we don't have to do anything with the bucket right now because that bucket is got some stuff we should need. I don't think we tell you to change the bucket. Now we want to just change projects. Yeah, there's no need for the bucket for this particular lab. Now if you are working with specific resources from that- from there you'd want to because all we're doing is setting up three environment variables. So all of this go ahead and run this block of code and see so it's printed out our API key and it printed out our project. Okay. The next we're going to import in the environment so we're basically going to set the environment variables for bucket and project to what we need them to be. And now, we're going to go from the Google API client discovery, we want to go and import that so that we can work with Google's APIs. And before we go any farther though, we better make sure that the API is we want to use are actually working. So we went in and set up our credentials, all was good. We went ahead and set up our project and we basically want to go through the API manager. We want to make sure that we have speech and that's enabled and we want to make sure that translates enabled and vision and language. Now you may find some projects have all that initialized already but let's double check. So I'm going to go over to library and I could actually click on and from here I don't necessarily need to search but the first one you want was speech and see how it says disable. Well that says it's enabled already. Great. Let's look for translation API. Translations enabled. Good. And let's look at vision, vision, yup this project, the project is initialized with everything it needs and we'll double check, natural language here. Yep, all those are good. Okay. So now we want to basically play around and work with our workbook to basically walk us through. So here we're looking for specific text in a corpus of scanned documents. So we've got a process here where we're going to basically take a bunch of files that are in the unstructured folder and then we want to list it. And we want to go ahead and pull the information out. So we'll go ahead and run that. Oh we did have an error. Why did we have an error? We did need our bucket. Okay. So we've got to plug in the appropriate bucket names. There we go, go to our data lab notebook. I knew it was there. We just didn't. We had to put in the project earlier but we didn't have you do the bucket. So let me go and grab my bucket name and my bucket name is the same as my project luckily and this is all those files we uploaded earlier. So let's put that in there. And now we'll run that block a coach our environment variables there. Now it looks like they also want us just to kind of plug it in here let's just make it work for sure. There's our bucket name because we're not specifying the permit. Sorry don't do it there. So now let me run this. Okay. So it's importing the images and this is the images, this is the graphics that we're actually looking for. So we wanted to pull out all this text in there. Okay. So it went ahead and ran. Good. This is just descriptive with graphics. And now we want to run the vision API to find things in there. So we want to search for 1 3 2 1. So we're going to go ahead and working through each of these photos looking for that text. You found that text in that file and it's looking at the other files so it's going through each of the files and only one of them seems to have had that text. So there we use the vision API to go and find a document that contain that data. Oh wait that was called snapshot too. But we know that's in our bucket. Let's look was it right. So we look at storage. We'll look at our bucket, unstructured and if we look at our photos, snapshot too. Ah look at that it found 1 3 2 1. So presumably we could ask you to look for 61.07. You know what I like to experiment when I'm working on things. So let's go out and say look for 61 0 7, 61.07 and where's going to rerun this job. So now it's going to go through each of the files. Look it found it. It found that file. It found that text in that image. Wow, that's pretty cool because that was just a graphic to begin with. You saw that, right? Everybody saw it was just a PNG file. Okay. Well the next demonstration we're in have you do in here is to translate a large document in parallel. So again, we're going to do google translate here. The API key will come from above and our files. Well Okay. It's going to pull the file from an existing bucket CPV public files. So we want that and it's going to do that on our cluster. Excellent. So we're in a quick run. Sets up our environment for us and two we're now going to tell it to run this, so it's grabbing the file-- Alice in Wonderland. And basically, now it's processing it and then when we do the last part we're going to have it translate it because we need to take that file and we're going to have it do translation. Oh and look at that. It's translated into Looks like Spanish for us. Perfect. Now the only that cling on for us because Alice in Wonderland is best written in the original cling on. Alright. So the last is sentiment analysis in parallel. What we're going to do is have it take a look a text and basically give us the general sentiment about that. So again I'm going to say run. It's going to work through it's going to use it and then we're going to go ahead and it's processing the file and then we're going to run it and it's going to use BigQuery to do it. It's going to actually go through hacker news stories and find us some useful information about that. The queries running, it's going to has pulled out some rows, and then last we're going to ask us. Okay. Here we go. There's our data, we're going to ask it to go ahead and extract the text from there and it's going to give us sort of a rating on the 10 articles that read on a scale. And you know a score greater than zero is a positive article, a score less than zero is a negative article. And basically they've looked this sentiment is it a positive or negative. So for the 10 articles that we read, you know how to teach a 12 year old how to make a javascript app. Okay. So that's one of them, and that was kind of a positive article. That's good. So I'm going to go ahead and print article- another article as for number three. How to teach. Sorry we wanted to do three articles sorry. So there was fundamentals and here's some more, revision pipeline. And again, it's able to take the information and give us some results. Okay. So that's the idea behind what we had you play with and this is also giving you a framework to work with the information that's coming out of data lab worksheet or a data log notebook and work with it in relation to all of the various APIs we get through it to. So a good sample starting point, you can now play with this, put your own data in there and you're good to go. So the last thing you might want to do is remember where these are all coming out of Github. So if you wanted to play with these at a later point you could actually just go to the github and get the latest version of these python notebooks. But you can also download the notebooks for later reference too, if you want. Okay. Well hopefully you've enjoyed this lab series. I think we've got one or two more slides in the slide deck and then you're all set and go build some fabulous applications in Google Cloud platform.
