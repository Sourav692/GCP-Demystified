Welcome to Google Cloud platform, this is Grant Morell. Today we're going to look at Cloud Dataproc which is Google's managed Hadoop infrastructure.

Our agenda is to talk about unstructured data, why we would use Cloud Dataproc, how to create a Cloud Dataproc cluster, and some customizations to the computing nodes of the cluster.

So let's begin. So for the last several years Google has been creating Google Street View by driving specially outfitted cars with lots of cameras on top around cities and creating street view of those cities. When they initially did this, they were doing it for use with Google Maps and Google Street View, but since the data set has been created now and actually is being updated rather frequently, it could be applied to so many other things beyond what's happening just within Google with it.

Look at this image. What can we tell? Well we have street signs. We have street names. We have street numbers. We have business names. We have traffic signals. We have business facades and frontage. We have a one time snapshot as to how many people are in front of it, and presumably we've got time of day and the data was taken sort of thing.

Now I've heard of organizations in New York that are actually using street view to document street parking spaces, disabled parking spaces, curbs, curbs that support wheelchairs, sidewalks, bus stops, windows and even trees, yeah trees. By combining satellite views they can identify trees from overhead, so using Google maps. Then they move down the street view, because from the map they can get the latitude and longitude coordinates and then use the vision API to identify the type of that tree. That way they can actually look at the types of trees and know the population of different types of trees around a city.

Wow! That's pretty cool. The alternative would be to have somebody walk around the city and actually document them all. Now, with something like Google Street View, the streets can be virtually driven and business opportunities can be looked for. We could look at windows you know, going beyond just you know, what we've identified so far, we can look at windows, we can look at railings. We could look at stonework, we could look at painting. You can look at grass mowing that needs be done. So there's a lot of data that could actually be determined by just processing an image. Now some big data involves just pure counting.

Data error rates go down when a bug fix was applied. Something that a computer could count. You know retail store, calculating delays in payment processing to identify stores experiencing problems with their credit card machines and things like that. Stuff that literally is purely quantitative. So it's got a quantity related to it. We need to collect that quantity and we need to look for thresholds. But, there are then those problems that require a lot of counting plus the human insight into looking at the data. So if I was to ask a question, OK my programmers are checking "code" but are there any specific programmers checking in low quality code. Well how would we know?

 Obviously we would need to create some sort of metric or we would have to set aside some sort of metric based on the data we have. We just haven't processed it yet. Now we might say well which of our stores is lacking parking spaces. How would we know? Well that would be video footage of our parking lot and looking and identifying when our parking space is in use, when are they not and is there ever a time of day where we exceed the parking spaces that we actually have allocated and people are waiting or people are leaving?
